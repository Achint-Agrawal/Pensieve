1. Ever notice how every AI agent you use forgets who you are the moment you close the tab? Your context is scattered and vendor locked.
2. Today’s LLM agents don’t actually know you — they only peek at the narrow slice of data you surrender to that platform. Your memory is fragmented and none of it is truly yours.
3. Meet Pensieve. Your portable, user‑owned memory layer for AI. Pensieve unifies your interactions and knowledge across platforms, so any agent you authorize can finally act with real context — your context.
4. In the foreground, the browser extension observes approved moments turning them into structured memories. In the background, connected data sources periodically enrich that knowledge graph.
5. Semantic and Contextual memories are stored in the Cosmos DB vector database for fast recall. Based on recent context, existing memories can be updated, deleted or added to the vector index.
6. For episodic or procedural memories, a knowledge graph, maintained using Graphiti and Neo4j, is incrementally updated. Each node is an entity and edges represent relationships. As newer context arrives, the graph is accordingly updated to reflect new information.
7. When needed, memories are extracted using vector search and nearest neighbor techniques to find relevant prior context.
8. This approach offers several advantages compared to traditional methods. Retrieval is faster, cost is lower and recall is higher.
9. These memories can then be surfaced at relevant places to provide richer, more personalized AI experiences.
10. All of this happens with complete user ownership and control. In the dashboard you can view, edit, delete memories, and toggle or revoke any source — ingestion stops instantly. Delete a memory and it’s truly gone: purged from the vector index and the graph, not just hidden.
11. Over time, platforms won’t need their own siloed memories — they can simply plug into yours.
12. Pensieve: Unified Memory. Truly Yours.
